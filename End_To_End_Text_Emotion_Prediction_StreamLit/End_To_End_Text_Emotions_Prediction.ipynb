{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c71cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1da341",
   "metadata": {},
   "source": [
    "## StreamLit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06436c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 19:37:10.286 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\deept\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "st.write(\"# Text Emotions Prediction\")\n",
    "t1 = st.text_input(\"Enter any text>>: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e88088",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fb6b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n"
     ]
    }
   ],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file,'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label,text])\n",
    "        return data\n",
    "\n",
    "file = \"text_emot.txt\"\n",
    "data = read_data(file)\n",
    "print(\"Number of instances: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08027f89",
   "metadata": {},
   "source": [
    "## Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da22e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token,n):\n",
    "    output = []\n",
    "    \n",
    "    for i in range(n-1,len(token)):\n",
    "        ngram = \" \".join(token[i-n+1:i+1])\n",
    "        output.append(ngram)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def create_features(text,nrange=(1,1)):\n",
    "    text_features = []    \n",
    "    text = text.lower()    \n",
    "    text_alphanum = re.sub('[^a-z0-9#]',' ',text)\n",
    "    \n",
    "    for n in range(nrange[0],nrange[1]+1):\n",
    "        text_features += ngram(text_alphanum.split(),n)\n",
    "        \n",
    "    text_punc = re.sub('[a-z0-9]',\" \",text)\n",
    "    \n",
    "    text_features += ngram(text_punc.split(),1)\n",
    "    \n",
    "    return Counter(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fad38a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'i': 1, 'love': 1, 'you': 1, '!': 1})\n",
      "Counter({'aly': 1, 'wins': 1, 'the': 1, 'gold': 1, '!!!': 1})\n",
      "Counter({'aly': 1, 'wins': 1, 'the': 1, 'gold': 1, 'aly wins': 1, 'wins the': 1, 'the gold': 1, '!!!!!': 1})\n"
     ]
    }
   ],
   "source": [
    "print(create_features(\"I love you!\"))\n",
    "print(create_features(\" aly wins the gold!!!\"))\n",
    "print(create_features(\" aly wins the gold!!!!!\", (1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff781fc",
   "metadata": {},
   "source": [
    "## Convert Labels to Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d5ee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(item,name):\n",
    "    items = list(map(float,item.split()))\n",
    "    \n",
    "    label = \"\"\n",
    "    \n",
    "    for idx in range(len(items)):\n",
    "        if items[idx] == 1:\n",
    "            label += name[idx] +\" \"\n",
    "            \n",
    "    return label.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30118fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "for label,text in data:\n",
    "    y_all.append(convert_label(label,emotions))\n",
    "    X_all.append(create_features(text,nrange=(1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764bea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features example: \n",
      "Counter({'time': 2, 'we': 2, 'met': 2, 'during': 1, 'the': 1, 'period': 1, 'of': 1, 'falling': 1, 'in': 1, 'love': 1, 'each': 1, 'that': 1, 'and': 1, 'especially': 1, 'when': 1, 'had': 1, 'not': 1, 'for': 1, 'a': 1, 'long': 1, 'during the': 1, 'the period': 1, 'period of': 1, 'of falling': 1, 'falling in': 1, 'in love': 1, 'love each': 1, 'each time': 1, 'time that': 1, 'that we': 1, 'we met': 1, 'met and': 1, 'and especially': 1, 'especially when': 1, 'when we': 1, 'we had': 1, 'had not': 1, 'not met': 1, 'met for': 1, 'for a': 1, 'a long': 1, 'long time': 1, 'during the period': 1, 'the period of': 1, 'period of falling': 1, 'of falling in': 1, 'falling in love': 1, 'in love each': 1, 'love each time': 1, 'each time that': 1, 'time that we': 1, 'that we met': 1, 'we met and': 1, 'met and especially': 1, 'and especially when': 1, 'especially when we': 1, 'when we had': 1, 'we had not': 1, 'had not met': 1, 'not met for': 1, 'met for a': 1, 'for a long': 1, 'a long time': 1, 'during the period of': 1, 'the period of falling': 1, 'period of falling in': 1, 'of falling in love': 1, 'falling in love each': 1, 'in love each time': 1, 'love each time that': 1, 'each time that we': 1, 'time that we met': 1, 'that we met and': 1, 'we met and especially': 1, 'met and especially when': 1, 'and especially when we': 1, 'especially when we had': 1, 'when we had not': 1, 'we had not met': 1, 'had not met for': 1, 'not met for a': 1, 'met for a long': 1, 'for a long time': 1, ',': 1, '.': 1})\n",
      "Label example:\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "print(\"features example: \")\n",
    "print(X_all[0])\n",
    "print(\"Label example:\")\n",
    "print(y_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55999b7c",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ed3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_all,y_all,test_size=0.2,random_state=123)\n",
    "\n",
    "def train_test(clf,X_train,X_test,y_train,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    train_acc = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test,clf.predict(X_test))\n",
    "    return train_acc,test_acc\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vect = DictVectorizer(sparse=True)\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0eb520",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2667a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Classifier                | Training Accuracy | Test Accuracy |\n",
      "| ------------------------- | ----------------- | ------------- |\n",
      "| SVC                       |         0.9067513 |     0.4512032 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deept\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
      "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
      "| DecisionTreeClassifier    |         0.9988302 |     0.4598930 |\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "lsvc = LinearSVC(random_state=123)\n",
    "rforest = RandomForestClassifier(random_state=123)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "clifs = [svc,lsvc,rforest,dtree]\n",
    "\n",
    "# train and test them \n",
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "\n",
    "for clf in clifs:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_acc,test_acc = train_test(clf,X_train,X_test,y_train,y_test)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b89b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    }
   ],
   "source": [
    "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "l.sort()\n",
    "label_freq = {}\n",
    "\n",
    "for label, _ in data:    \n",
    "    #print(label)\n",
    "    label_freq[label] = label_freq.get(label,0) + 1\n",
    "    #print(label_freq)\n",
    "    \n",
    "label_freq\n",
    "\n",
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq,key=label_freq.get,reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b823e",
   "metadata": {},
   "source": [
    "## Working via UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e1ef195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "guilt\n"
     ]
    }
   ],
   "source": [
    "emoji_dict = {\"joy\":\"😂\", \"fear\":\"😱\", \"anger\":\"😠\", \"sadness\":\"😢\", \"disgust\":\"😒\", \"shame\":\"😳\", \"guilt\":\"😳\"}\n",
    "\n",
    "texts = [t1]  #Getting user input from streamlit UI\n",
    "\n",
    "for text in texts:\n",
    "    features = create_features(text,nrange=(1,4))\n",
    "    features = vect.transform(features)\n",
    "    #print(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    print(prediction)\n",
    "    st.write(emoji_dict[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c5830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35754665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aec2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd1170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0053470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679d7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8370a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08daf251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eea7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
